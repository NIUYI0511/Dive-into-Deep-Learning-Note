# D2L--lesson12 卷积层

## 从全连接到卷积

多层感知机十分适合处理表格数据，其中行对应样本，列对应特征。 对于表格数据，我们寻找的模式可能涉及特征之间的交互，但是我们不能预先假设任何与特征交互相关的先验结构。

对于高维感知数据，这种缺少结构的网络可能会变得不实用。

图像中本就拥有丰富的结构，而这些结构可以被人类和机器学习模型使用。 *卷积神经网络*（convolutional neural networks，CNN）是机器学习利用自然图像中一些已知结构的创造性方法。

### 不变性

1. *平移不变性*（translation invariance）：不管检测对象出现在图像中的哪个位置，神经网络的前面几层应该对相同的图像区域具有相似的反应，即为“平移不变性”。
2. *局部性*（locality）：神经网络的前面几层应该只探索输入图像中的局部区域，而不过度在意图像中相隔较远区域的关系，这就是“局部性”原则。最终，可以聚合这些局部特征，以在整个图像级别进行预测。

$$
[\mathbf{H}]_{i, j} = u + \sum_{a = -\Delta}^{\Delta} \sum_{b = -\Delta}^{\Delta} [\mathbf{V}]_{a, b} [\mathbf{X}]_{i+a, j+b}.
$$

这玩意就是一个卷积层，V被称为卷积核，或者说滤波器，亦或简单称其为该卷积层的权重，是可以学习的参数。

参数⼤幅减少的代价是，我们的特征现在是平移不变的，并且当确定每个隐藏活性值时，每⼀层只包含局部的信息

以上所有的权重学习都将 依赖于归纳偏置。当这种偏置与现实相符时，我们就能得到样本有效的模型，并且这些模型能很好地泛化到 未知数据中。但如果这偏置与现实不符时，⽐如当图像不满⾜平移不变时，我们的模型可能难以拟合我们的 训练数据。

### 卷积

在数学中，两个函数（比如\(f, g: 
$$
\mathbb{R}^d \to \mathbb{R}
$$
\)）之间的“卷积”被定义为
$$
(f * g)(\mathbf{x}) = \int f(\mathbf{z}) g(\mathbf{x}-\mathbf{z}) d\mathbf{z}.
$$
卷积是当把⼀个函数“翻转”并移位x时，测量f和g之间的重叠。当为离散对象时，积分就变成求和。

对于⼆维张量，则为f的索引(a, b)和g的索引(i − a, j − b)上的对应加和：
$$
(f * g)(i, j) = \sum_a\sum_b f(a, b) g(i-a, j-b).
$$

### 通道

之前忽略了图像一般包含三个通道（三种原色）。 实际上，图像不是二维张量，而是一个由高度、宽度和颜色组成的三维张量。

由于输⼊图像是三维的，我们的隐藏表示H也最好采⽤三维张量。换句话说，对于每⼀个空间位置，我们想要采⽤⼀组⽽不是⼀个隐藏表⽰。这样⼀组隐藏表⽰可以想象成⼀些互相堆叠的⼆维⽹格。因此，我们可以把隐藏表⽰想象为⼀系列具有⼆维张量的通道（channel）。这些通道有时也被称为特征映射（feature maps），因为每个通道都向后续层提供⼀组空间化的学习特征。直观上你可以想象在靠近输⼊的底层，⼀些 通道专⻔识别边缘，⽽⼀些通道专⻔识别纹理。

## 图像卷积

### 互相关运算

严格来说，卷积层是个错误的叫法，因为它所表达的运算其实是*互相关运算*（cross-correlation）

在卷积层中，输入张量和核张量通过互相关运算产生输出张量。

![../_images/correlation.svg](https://zh-v2.d2l.ai/_images/correlation.svg)

在二维互相关运算中，卷积窗口从输入张量的左上角开始，从左到右、从上到下滑动。 当卷积窗口滑动到新一个位置时，包含在该窗口中的部分张量与卷积核张量进行按元素相乘，得到的张量再求和得到一个单一的标量值，由此我们得出了这一位置的输出张量值。

输出⼤⼩等于输⼊⼤⼩nh × nw减去卷积核⼤⼩kh × kw，即：
$$
(n_h-k_h+1) \times (n_w-k_w+1).
$$
实现二维卷积：

```python
import torch
from torch import nn
from d2l import torch as d2l

def corr2d(X, K):  #@save
    """计算二维互相关运算"""
    h, w = K.shape
    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))
    for i in range(Y.shape[0]):
        for j in range(Y.shape[1]):
            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()
    return Y
```

```python
X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])
K = torch.tensor([[0.0, 1.0], [2.0, 3.0]])
corr2d(X, K)
```

输出：

tensor([[19., 25.],
        [37., 43.]])

### 卷积层

卷积层对输入和卷积核权重进行互相关运算，并在添加标量偏置之后产生输出。 

卷积层中的两个被训练的参数是卷积核权重和标量偏置。

```python
class Conv2D(nn.Module):
    def __init__(self, kernel_size):
        super().__init__()
        self.weight = nn.Parameter(torch.rand(kernel_size))
        self.bias = nn.Parameter(torch.zeros(1))

    def forward(self, x):
        return corr2d(x, self.weight) + self.bias
```

* 一个小例子：目标边缘检测

* ```python
  #创建一个简单的黑白图像X
  X = torch.ones((6, 8))
  X[:, 2:6] = 0
  #构造卷积核，当进行互相关运算时，如果水平相邻的两元素相同，则输出为零，否则输出为非零
  K = torch.tensor([[1.0, -1.0]])
  
  Y = corr2d(X, K)
  Y
  ```

输出：

tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],
        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],
        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],
        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],
        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],
        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])

注意：该卷积核不能检测水平边缘

### 学习卷积核

当有了更复杂数值的卷积核，或者连续的卷积层时，我们不可能手动设计滤波器。

通过仅查看“输入-输出”对来学习由`X`生成`Y`的卷积核。

先构造一个卷积层，并将其卷积核初始化为随机张量。接下来，在每次迭代中，我们比较`Y`与卷积层输出的平方误差，然后计算梯度来更新卷积核。

```python
# 构造一个二维卷积层，它具有1个输出通道和形状为（1，2）的卷积核
conv2d = nn.Conv2d(1,1, kernel_size=(1, 2), bias=False)

# 这个二维卷积层使用四维输入和输出格式（批量大小、通道、高度、宽度），
# 其中批量大小和通道数都为1
X = X.reshape((1, 1, 6, 8))
Y = Y.reshape((1, 1, 6, 7))
lr = 3e-2  # 学习率

for i in range(10):
    Y_hat = conv2d(X)
    l = (Y_hat - Y) ** 2
    conv2d.zero_grad()
    l.sum().backward()
    # 迭代卷积核
    conv2d.weight.data[:] -= lr * conv2d.weight.grad
    if (i + 1) % 2 == 0:
        print(f'epoch {i+1}, loss {l.sum():.3f}')
```

输出：

epoch 2, loss 1.618
epoch 4, loss 0.298
epoch 6, loss 0.061
epoch 8, loss 0.015
epoch 10, loss 0.004

```python
conv2d.weight.data.reshape((1, 2))
```

输出：

tensor([[ 0.9879, -0.9993]])

### 特征映射与感受野

在卷积神经网络中，对于某一层的任意元素\(x\)，其*感受野*（receptive field）是指在前向传播期间可能影响\(x\)计算的所有元素（来自所有先前层）

感受野可能大于输入的实际大小

当一个特征图中的任意元素需要检测更广区域的输入特征时，我们可以构建一个更深的网络。