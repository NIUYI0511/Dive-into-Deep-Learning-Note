# D2L--lesson14 填充、步幅、多输入输出通道、池化层

## 填充

已知卷积的输出形状取决于输入形状和卷积核的形状

有时，在应用了连续的卷积之后，我们最终得到的输出远小于输入大小。这是由于卷积核的宽度和高度通常大于1所导致的。原始图像的边界丢失了许多有⽤信息

填充可以解决这个问题：

在输⼊图像的边界填充元素（通常填充元素是0）

![../_images/conv-pad.svg](https://zh-v2.d2l.ai/_images/conv-pad.svg)

通常，如果我们添加\(p_h\)行填充（大约一半在顶部，一半在底部）和\(p_w\)列填充（左侧大约一半，右侧一半），则输出形状将为
$$
(n_h-k_h+p_h+1)\times(n_w-k_w+p_w+1).
$$
在许多情况下，我们需要
$$
设置p_h=k_h-1和p_w=k_w-1
$$
，使输入和输出具有相同的高度和宽度。

假设\(k_h\)是奇数，我们将在高度的两侧填充\(p_h/2\)行。

假设\(k_h\)是偶数，则一种可能性是
$$
在输入顶部填充\lceil p_h/2\rceil行，在底部填充\lfloor p_h/2\rfloor行
$$
卷积神经网络中卷积核的高度和宽度通常为奇数，例如1、3、5或7。 选择奇数的好处是，保持空间维度的同时，我们可以在顶部和底部填充相同数量的行，在左侧和右侧填充相同数量的列。



创建一个高度和宽度为3的二维卷积层，并在所有侧边填充1个像素。给定高度和宽度为8的输入，则输出的高度和宽度也是8:

```python
import torch
from torch import nn


# 为了方便起见，我们定义了一个计算卷积层的函数。
# 此函数初始化卷积层权重，并对输入和输出提高和缩减相应的维数
def comp_conv2d(conv2d, X):
    # 这里的（1，1）表示批量大小和通道数都是1
    X = X.reshape((1, 1) + X.shape)
    Y = conv2d(X)
    # 省略前两个维度：批量大小和通道
    return Y.reshape(Y.shape[2:])

# 请注意，这里每边都填充了1行或1列，因此总共添加了2行或2列
conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1)
X = torch.rand(size=(8, 8))
comp_conv2d(conv2d, X).shape
```

输出：

torch.Size([8, 8])

可以填充不同的高度和宽度，使输出和输入具有相同的高度和宽度。

```python
conv2d = nn.Conv2d(1, 1, kernel_size=(5, 3), padding=(2, 1))
comp_conv2d(conv2d, X).shape
```

输出：

torch.Size([8, 8])

## 步幅

前面的例子中，我们默认每次滑动一个元素。 但是，有时候为了高效计算或是缩减采样次数，卷积窗口可以跳过中间位置，每次滑动多个元素。

每次滑动元素的数量称为*步幅*（stride）

![../_images/conv-stride.svg](https://zh-v2.d2l.ai/_images/conv-stride.svg)

通常，当垂直步幅为\(s_h\)、水平步幅为\(s_w\)时，输出形状为
$$
\lfloor(n_h-k_h+p_h+s_h)/s_h\rfloor \times \lfloor(n_w-k_w+p_w+s_w)/s_w\rfloor.
$$
如果我们设置了\(p_h=k_h-1\)和\(p_w=k_w-1\)，则输出形状将简化为
$$
\lfloor(n_h+s_h-1)/s_h\rfloor \times \lfloor(n_w+s_w-1)/s_w\rfloor\
$$
 更进一步，如果输入的高度和宽度可以被垂直和水平步幅整除，则输出形状将为
$$
(n_h/s_h) \times (n_w/s_w)
$$


将高度和宽度的步幅设置为2，从而将输入的高度和宽度减半。

```python
conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1, stride=2)
comp_conv2d(conv2d, X).shape
```

输出：

torch.Size([4, 4])

```python
conv2d = nn.Conv2d(1, 1, kernel_size=(3, 5), padding=(0, 1), stride=(3, 4))
comp_conv2d(conv2d, X).shape
```

输出：

torch.Size([2, 2])

默认情况下，填充为0，步幅为1。在实践中，我们很少使⽤不⼀致的步幅或填充，也就 是说，我们通常有
$$
p_h = p_w和s_h = s_w。
$$

## 多输入通道

![img](https://i0.hdslb.com/bfs/note/6e067b12adc70bb1aa727215ce6f7cb1a11b9d48.png)

- mnist数据集中的图片是灰度图片，只有一个通道
- 一张彩色图片是由红绿蓝三个通道组成的，所以图片在表示的时候通道数是3



例（输入是一个三维的tensor）

![img](https://i0.hdslb.com/bfs/note/d7ee765fe2de0f7b831c0606758c5f55da385251.png)

- 每一个通道都有对应的卷积核
- 每个通道的输入和对应通道的卷积核做卷积，然后将得到的各个通道上的输出进行叠加（对应位置上的元素相加）得到最终的结果
- 计算公式如下图所示

![img](https://i0.hdslb.com/bfs/note/417d88b160da67832871774382ae757c9ba6564f.png)

- 输出是单通道的，不管输入有多少个通道，输出是他们输出结果的叠加，所以始终是单通道

## 多输出通道

![img](https://i0.hdslb.com/bfs/note/a95bcaf603d6035b6214dc710717fd5847462872.png)

- 为什么要有多个输出通道？因为不管有多少个输入通道只会得到单输出通道的话是不够的
- 如果对每一个输出通道有一个三维的卷积核，这个卷积核会输出自己的通道（就相当于在三维的基础上又加了一维 i ，这一维表示输出的通道数）
- 这里输入和输出通道是没有相关性的

## 多个输入和输出特征

![img](https://i0.hdslb.com/bfs/note/a8a3bb0e6b39a28d6233cc45c268527a2d14212b.png)

- 每个输出通道可以认为是在识别某一个特定的模式（特征），通过学习不同卷积核的参数来匹配某一个特定的模式

  **多输入输出通道 P1 - 08:02**

- 从某一层的角度来看，输入通道的卷积核可以将上一层得到的不同模式进行识别和组合，按照一定的权重进行相加组合，得到了组合的模式识别

  **多输入输出通道 P1 - 08:59**

- 对于一个深度的神经网络来说，下面的一些层的不同通道用来识别一些不同的局部的底层信息（边、纹理），越往上，上层会将局部的纹理组合起来，变成更加高级，较之前更加整体性的模式（特征，如耳朵、胡须等），最上面将所有识别的模式组合起来就形成了所要识别的类别（猫）

### **1\*1的卷积层**

![img](https://i0.hdslb.com/bfs/note/d85f3c6031775069751fb19ad39fe313b9d0e6ef.png)

- 卷积核的高和宽都等于1，意味着它不会识别空间信息，因为他每次只看一个空间像素所以不会去识别通道中的空间信息

- 输出的值等价于将对应的输入位置上的不同通道上的值做加权和

- 1×1卷积核的作用就是去融合不同通道的信息可以认为是不做空间的匹配，只是在输入层直接做输入通道和输出通道的融合，等价于将整个输入拉成一个向量，通道数等于feature的数量，卷积核相当于一个co*ci的全部连接层

  **多输入输出通道 P1 - 11:34**

- 1*1的卷积层就等价于一个全连接层，不做任何的控制信息，因为全连接层不考虑空间信息它只考虑在特征维度（也就是输入通道维数）的融合

- 它是一个特殊的卷积层

### **二维卷积层**

![img](https://i0.hdslb.com/bfs/note/a413e00940cf7e9ac6330de0d8a25ae3ab32d4d0.png)

- 复杂度（需要的浮点运算的程度）的计算

### **总结**

![img](https://i0.hdslb.com/bfs/note/47dd20e0926bbc8fba2ea0e52cf541b43473d34c.png)

- 输入通道数不是卷积层的超参数，它是前一层的
- 所以最后的卷积核是一个4维的张量

## **池化层**

### 卷积层对位置信息是非常敏感的

![img](https://i0.hdslb.com/bfs/note/0e040b9857307abdf74010df09ddde62136ae488.png)

- x最左边第二列和第三列中间有一个边缘，如果用一个1*2的卷积核（一边是1，一边是-1），就会在输出的第二列全部为1，也就意味着将边缘全部检测出来了，但是这一列的左边是0右边也是0，也就是说它对位置是非常敏感的，一个像素的偏移就会导致0输出
- 所以这不是一件特别好的事情，因为边缘在真实图片中很有可能不是很规矩，可能会有弯曲的地方，而且相机的抖动或者物体的移动都会导致边缘发生变化，所以需要一定的平移不变性（输入稍微有一点改动，输出不会有太大的变化，减低卷积核对位置的敏感程度）

### **二维最大池化**

![img](https://i0.hdslb.com/bfs/note/76aa7de93db452433099c16bd593f350ee321f06.png)

- 工作原理和卷积有点类似，有一个窗口在输入上滑动，得到输出
- 但是这里的操作不是像卷积核一样让卷积核和输入做点积然后加起来，而是每一次将滑动窗口中的最大值取出来作为输出值（最大池化）
- 简单来讲就是用滑动窗口来计算输出，但是每一次不用核做计算，而是将滑动窗口中的最大值输出

![img](https://i0.hdslb.com/bfs/note/279997c17f419b0a118ebd548211413722f5aa20.png)

- 上图的目的是要做垂直边缘检测，最左边的矩阵是输入，中间的矩阵是卷积输出，如果在卷积输出的基础上再做一次2*2的最大池化可以得到最右边的矩阵（上图中最右边的矩阵多了一列1）
- 上图中可以发现2*2得最大池化层可以容忍最大1个像素的偏移
- 最大池化层可以允许输入发生一定程度上的小偏移，而且作用在卷积输出上，可以增加一点模糊化的效果

### **池化层的其他超参数：填充、步幅和多个通道**

![img](https://i0.hdslb.com/bfs/note/0d77426b05d75fdff38e9e04efc71e3a738deae0.png)

- 填充和步幅是和卷积类似的两个超参数
- 池化没有可以学习的参数，它不需要学习核里面的参数，因为他就是一个取最大值的操作
- 池化层作用于多输入通道的输入的时候，对每一个输入通道都做一次池化层的操作得到对应的输出通道，而不像卷积一样可以融合多个通道，池化是不会融合多个通道的，他是每一个通道做一次池化层，也就意味着输出的通道数是等于输入通道数的，相对来说比较简单
- 池化操作为什么不做多通道的融合？因为多通道融合可以交给卷积来进行，就可以将池化层做的相对比较简单

### **平均池化层**

![img](https://i0.hdslb.com/bfs/note/99eb7ecdd15c5ebad4a81eddbb71673d405d2c23.png)

- 另外一个常用的池化层，就是将最大池化层中取最大值的操作变成求平均值的操作
- 最大池化层和平均池化层的区别：最大池化层输出的是每个窗口中最强的信号，平均池化层输出的是每个窗口中平均的信号强度

**总结**

![img](https://i0.hdslb.com/bfs/note/3a93081f7ffc46b5bb934911cf15125a5a79049f.png)

- 池化层的主要作用是用来缓解卷积层位置的敏感性
- 通常池化层之作用在卷积层的后面
- 池化层和卷积层不一样的地方在于池化层对每个通道分别作用、直接输出，没有输出通道数这个超参数，输入通道数是一定等于输出通道数的
- 池化层没有可以学习的超参数，所以池化层是不会使模型变大的